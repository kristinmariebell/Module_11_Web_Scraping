# Module_11_Web_Scraping
Hello! 
I created copies of the start codes for part 1 and part 2 in order to keep them in tact, 
and worked on the code in my jupyter notebooks labeled "part_1_mars_news" and "part_2_mars_weather"
Part 1 tasks included scraping the "mars_news" website to extract all text elements, storing those elements
in a dictiionary and looping through to extract the title and preview for each article on the site.
Part 2 tasks included scraping the "mars_facts" website to extract the rows of data from the table, 
createing a DataFrame with the data and performing analysis from that information
I did some data cleaning by changing the data types in the DataFrame to aid analysis
I determinted that there are 12 months on Mars and that there are 1867 Martian days worth of data collected
I found the average low temperature by month and determinted that 'month 3' has the coldest temperatures (around -85) 
and 'month 8' has the warmest temperatures (around -70)
I found the average pressure by month and determined that 'month 6' has the lowest pressue values (around 775) 
and 'month 9' has the highest pressure values (around 975)
I found the amount of terrestrial days in a Martian year by researching that the degree of solar longitude is what determines
the length of a year. I used the solar longitude data and the terrestrial_data data to determine that there are 687 
earth days in a Martian year
I then plotted all minimun temperature data collected and exported the DataFrame to a CSV file

I used ChatGPT for help with some coding questions, and referred to the module activities for coding examples
